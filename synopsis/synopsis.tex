\documentclass[12pt,a4paper,twocolumn]{article}
\usepackage{times} % times font
\usepackage{mathptmx} % times font in maths
\usepackage[top=0.65in, bottom=0.65in, left=0.65in, right=0.65in]{geometry}
\usepackage{multirow} %in tables
\usepackage{caption} % in tables
\pagenumbering{gobble}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\usepackage[pdftex]{graphicx}
\usepackage{lipsum}
\usepackage{amsmath}

% \usepackage{hyperref}
% \usepackage{subfigure}
% \usepackage{indentfirst} % indent frst paragraph of section
% \usepackage[usenames,dvipsnames]{color}
\newcommand{\ts}{\textsuperscript}

\begin{document}

\twocolumn[
\begin{@twocolumnfalse}
\begin{center}
	\begin{large}
	{\HRule \\[0.2cm]}
	\textsc{Instance-wise thresholding methods for multi-label classification}
	{\HRule \\[0.3cm]}
	\end{large}

	\begin{minipage}{ 0.44\textwidth }
		\begin{flushleft}
			\textit{Author:}\\
			Kacper \textbf{Sokol}
		\end{flushleft}
	\end{minipage}
	\begin{minipage}{ 0.44\textwidth }
		\begin{flushright}
			{\textit{Supervisors:}\\
			Peter \textbf{Flach}, Meelis \textbf{Kull}\\[0.3cm]}
		\end{flushright}
	\end{minipage}
\end{center}
\end{@twocolumnfalse}
]

\section*{\texttt{Review}}
This work will cover instance-wise thresholding on multi-label ranking and scoring. To be more precise, we will examine choosing a threshold based on particular data instance features on ordered(according to their relevance) list of labels.\\
We are going to evaluate performance of such task measured on high cardinality: \emph{delicious}($19.020$) and average cardinality: \emph{yeast}($4.237$) and \emph{mediamill}($4.376$) datasets.\\ % Additionally we will draw the histogram of of labels per instance to visualise distributions of labels.
To train the classifiers and rank corresponding test instances we will use: \emph{MEKA}, \emph{Mulan} and independent implementation of \emph{Probabilistic Classifiers Chains}.\\
As evaluation measures we plan to employ example based measures: \emph{recall}, \emph{precision}, \emph{$F_\beta$}, \emph{accuracy}, and \emph{hamming loss}; and label based measures: \emph{macro-averaging} and \emph{micro-averaging}.%; ranking measures: \emph{one-error}, \emph{coverage}, \emph{ranking loss} and \emph{average precision}; finally we will also use \emph{hierarchical-loss}.\\

\section*{\texttt{Multi-label ranking}}
Multi-label ranking is used to order the labels according to their relevance given particular instance. On the other, hand scoring algorithms output score per label for each instance thus they facilitate labels ordering.\\
Next step is to apply thresholding algorithm to select relevant number of labels per instance.\\
For our experiment we will use the following ranking and scoring approaches:

explain each of them!\\

\begin{enumerate}
\item Rankings:
	\begin{itemize}
	\item Multi-label perceptron. %* ?????
	\item Ranking by pairwise comparison. %*
	% \item Calibrated label ranking. %*
	\item Ad-aBoost.MR. %*
	\end{itemize}
\item Scores:
	\begin{itemize}
	\item Random k-Labelsets a.k.a.\ RAkEL---label power-set. %*
	% \item Ensembles of pruned set---label power-set.
	\item Ensembles of classifier chains---pruned sets i.e.\ extension of label power-set which reduces cardinality. % ?????
	\item Some probabilistic classifiers.???
	\end{itemize}
\end{enumerate}

For the approaches based on binary or multi-class solutions we aim to test them with: \emph{k-NN}, \emph{SVM} and \emph{decision trees} algorithms.

\section*{\texttt{Data driven thresholding}}
We aim at applying the following data dependent thresholding methods:

explain each and every!\\


\begin{enumerate}
\item MetaLabeler---mapping from the feature vector to the number of labels per instance based on:
	\begin{itemize} % 05670068.pdf
	\item Original input space.
	\item Score vectors.
	\item Sorted score vectors.
	\end{itemize}
	and:
	\begin{itemize} % 05670068.pdf
	\item Regression.
	\item Multi-class classification.
	\end{itemize}

\item Artificial label for pairwise comparisons---PCC, EPCC, etc.
\item Artificial label for threshold extraction.
% \item Score per label\ts{*}. % assume we give the score of the label corresponding to relative frequency of this label according to data point and then cut at given fixed threshold---maybe
\item Threshold prediction---based on $t(x)$ minimizing:
	$$
	| \lambda_j \in Y : s_j(x) \leq t(x) | + | \lambda_j \in \Delta \text{\textbackslash{}} Y : s_j(x) \geq t(x) |
	$$
\end{enumerate}

Out of the top three MetaLabeler approaches the \emph{original input space} was discovered to be optimal. We will use this fact to restrict our experiment pool, therefore we will neither test \emph{score vectors} nor \emph{sorted score vectors}.\\

\section*{\texttt{Deliverables}}
Finally, we aim to ``compare and contrast'' acquired results according to aforementioned criteria. Our goal is to indicate winning data driven thresholding algorithm if possible and discover any dependencies that may arise between characteristic of a dataset, threshold approach, and chosen classification algorithm.\\

The main purpose of this experiment is to examine whether advanced, data dependent threshold selection outperforms simple, global thresholding---basic benchmark will be produced. Moreover, study will be done to check whether increase in computational complexity will significantly improve labeling and in what cases advanced approach is worth the slowdown.\\

We also aim at comparing 2\ts{nd} and 3\ts{rd} thresholding method against each other as they are very similar and their results may be hard to distinguish on the general test. The purpose of this subtask is to see whether introduced artificial label is necessary or it is enough to treat it as a truncation point.\\


% \begin{figure}[htbp]
% \centering
% \includegraphics[width=0.5\textwidth]{figures/figure4b.png}
% % \begin{tiny}
% \caption{Simulation of two interconnected neurons with inhibitory synapses.\label{fig:part4b}}
% % \end{tiny}
% \vspace{0.2cm}
% \end{figure}

\end{document}
